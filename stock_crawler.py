"""
Yahoo Finance ì£¼ì‹ ë°ì´í„° ìë™ í¬ë¡¤ëŸ¬
Python íŒŒì¼ í•˜ë‚˜ë§Œ ì‹¤í–‰í•˜ë©´ ìë™ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""
from crawler import YahooFinanceCrawler
import time
import sys


def crawl_with_selenium(url: str, max_rows: int = 50):
    """
    Seleniumì„ ì‚¬ìš©í•˜ì—¬ Yahoo Finance í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
    JavaScriptë¡œ ë™ì  ë¡œë”©ë˜ëŠ” í˜ì´ì§€ì— í•„ìš”í•©ë‹ˆë‹¤.
    """
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.service import Service
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        from webdriver_manager.chrome import ChromeDriverManager
    except ImportError:
        print("âŒ Seleniumì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install selenium webdriver-manager")
        return []
    
    print("ğŸŒ ë¸Œë¼ìš°ì €ë¥¼ ì‹œì‘í•˜ëŠ” ì¤‘...")
    
    # Chrome ì˜µì…˜ ì„¤ì •
    chrome_options = Options()
    chrome_options.add_argument('--headless')  # ë¸Œë¼ìš°ì € ì°½ì„ ë„ìš°ì§€ ì•ŠìŒ
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--window-size=1920,1080')
    chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    
    driver = None
    try:
        # ChromeDriver ìë™ ì„¤ì¹˜ ë° ì„¤ì •
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        
        print(f"ğŸ“¡ í˜ì´ì§€ ë¡œë”© ì¤‘: {url}")
        driver.get(url)
        
        # í…Œì´ë¸”ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
        print("â³ ë°ì´í„° ë¡œë”© ëŒ€ê¸° ì¤‘...")
        wait = WebDriverWait(driver, 30)
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'tr[data-testid="data-table-v2-row"]')))
        
        # ì¶”ê°€ ëŒ€ê¸° (JavaScript ë Œë”ë§ ì™„ë£Œë¥¼ ìœ„í•´)
        time.sleep(3)
        
        # HTML ê°€ì ¸ì˜¤ê¸°
        html_content = driver.page_source
        
        # í¬ë¡¤ëŸ¬ë¡œ íŒŒì‹±
        crawler = YahooFinanceCrawler()
        stocks = crawler.parse_html_table(html_content)
        
        return stocks[:max_rows] if stocks else []
        
    except Exception as e:
        print(f"âŒ Selenium í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return []
    finally:
        if driver:
            driver.quit()
            print("ğŸ”’ ë¸Œë¼ìš°ì €ë¥¼ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤.")


def crawl_with_requests(url: str, max_rows: int = 50):
    """
    requestsë¥¼ ì‚¬ìš©í•˜ì—¬ Yahoo Finance í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
    ê°„ë‹¨í•˜ì§€ë§Œ JavaScriptë¡œ ë™ì  ë¡œë”©ë˜ëŠ” ê²½ìš° ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    print(f"ğŸ“¡ í˜ì´ì§€ ìš”ì²­ ì¤‘: {url}")
    crawler = YahooFinanceCrawler()
    stocks = crawler.crawl_from_url(url, max_rows)
    return stocks


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 70)
    print("Yahoo Finance ì£¼ì‹ ë°ì´í„° ìë™ í¬ë¡¤ëŸ¬")
    print("=" * 70)
    
    # Yahoo Finance URL ì„¤ì •
    # ì‚¬ìš©ìê°€ ì›í•˜ëŠ” í˜ì´ì§€ URLë¡œ ë³€ê²½ ê°€ëŠ¥
    # ì˜ˆì‹œ: ìƒìŠ¹ì£¼, í•˜ë½ì£¼, ê±°ë˜ëŸ‰ ìƒìœ„ ë“±
    default_url = "https://finance.yahoo.com/screener/predefined/day_gainers"
    
    # ëª…ë ¹ì¤„ ì¸ìë¡œ URL ë°›ê¸°
    if len(sys.argv) > 1:
        url = sys.argv[1]
    else:
        url = default_url
    
    max_rows = 50
    
    print(f"\nğŸ“Š í¬ë¡¤ë§ ëŒ€ìƒ: {url}")
    print(f"ğŸ“ˆ ìµœëŒ€ ì¶”ì¶œ ê°œìˆ˜: {max_rows}ê°œ\n")
    
    # ë°©ë²• 1: requestsë¡œ ì‹œë„ (ë¹ ë¥´ì§€ë§Œ JavaScript í˜ì´ì§€ëŠ” ì‹¤íŒ¨í•  ìˆ˜ ìˆìŒ)
    print("ë°©ë²• 1: ê°„ë‹¨í•œ HTTP ìš”ì²­ ì‹œë„ ì¤‘...")
    stocks = crawl_with_requests(url, max_rows)
    
    # ë°©ë²• 2: ì‹¤íŒ¨í•˜ë©´ Selenium ì‚¬ìš© (ëŠë¦¬ì§€ë§Œ JavaScript í˜ì´ì§€ë„ ì²˜ë¦¬ ê°€ëŠ¥)
    if not stocks:
        print("\në°©ë²• 1 ì‹¤íŒ¨. ë°©ë²• 2: ë¸Œë¼ìš°ì € ìë™í™” ì‹œë„ ì¤‘...")
        print("(ì´ ë°©ë²•ì€ Chrome ë¸Œë¼ìš°ì €ê°€ í•„ìš”í•˜ë©° ì‹œê°„ì´ ë” ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        stocks = crawl_with_selenium(url, max_rows)
    
    if not stocks:
        print("\nâŒ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("\nê°€ëŠ¥í•œ ì›ì¸:")
        print("1. ì¸í„°ë„· ì—°ê²° ë¬¸ì œ")
        print("2. Yahoo Finance í˜ì´ì§€ êµ¬ì¡° ë³€ê²½")
        print("3. JavaScript ë™ì  ë¡œë”© í˜ì´ì§€ (Selenium í•„ìš”)")
        print("\ní•´ê²° ë°©ë²•:")
        print("- Seleniumì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸: pip install selenium webdriver-manager")
        print("- Chrome ë¸Œë¼ìš°ì €ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
        return
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nâœ… ì´ {len(stocks)}ê°œì˜ ì£¼ì‹ ë°ì´í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
    
    # ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
    crawler = YahooFinanceCrawler()
    output_file = 'stock_data.xlsx'
    crawler.save_to_excel(stocks, output_file)
    
    # ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥
    print("\n" + "=" * 70)
    print("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ê°œ)")
    print("=" * 70)
    for i, stock in enumerate(stocks[:5], 1):
        print(f"\n{i}. {stock.get('Symbol', 'N/A')} - {stock.get('Name', 'N/A')}")
        print(f"   ê°€ê²©: ${stock.get('Price', 'N/A')}")
        print(f"   ë³€ë™: {stock.get('Change', 'N/A')} ({stock.get('Change %', 'N/A')})")
        print(f"   ê±°ë˜ëŸ‰: {stock.get('Volume', 'N/A')}")
        print(f"   ì‹œê°€ì´ì•¡: {stock.get('Market Cap', 'N/A')}")
    
    if len(stocks) > 5:
        print(f"\n... ì™¸ {len(stocks) - 5}ê°œ ë”")
    
    print("\n" + "=" * 70)
    print(f"âœ… ì™„ë£Œ! '{output_file}' íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    print("=" * 70)


if __name__ == "__main__":
    main()

